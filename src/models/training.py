"""
Script d'entra√Ænement corrig√© pour la d√©tection de fraude
Version robuste avec gestion d'erreurs
"""

import pandas as pd
import numpy as np
import mlflow
import mlflow.sklearn
import logging
from pathlib import Path
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, 
    roc_auc_score, classification_report, confusion_matrix
)
from imblearn.over_sampling import SMOTE
import joblib
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RobustFraudTrainer:
    """Entra√Æneur robuste pour la d√©tection de fraude"""
    
    def __init__(self):
        # Configuration MLflow
        self.mlflow_uri = "http://localhost:5001"
        mlflow.set_tracking_uri(self.mlflow_uri)
        
        try:
            mlflow.set_experiment("fraud_detection_pipeline")
            self.mlflow_enabled = True
            logger.info(f"‚úÖ MLflow configur√©: {self.mlflow_uri}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è MLflow d√©sactiv√©: {e}")
            self.mlflow_enabled = False
    
    def load_data(self):
        """Charge les donn√©es pr√©trait√©es"""
        logger.info("üìä Chargement des donn√©es...")
        
        try:
            train_df = pd.read_csv("data/processed/train.csv")
            val_df = pd.read_csv("data/processed/validation.csv")
            test_df = pd.read_csv("data/processed/test.csv")
            
            logger.info(f"   ‚Ä¢ Train: {len(train_df)} lignes")
            logger.info(f"   ‚Ä¢ Validation: {len(val_df)} lignes") 
            logger.info(f"   ‚Ä¢ Test: {len(test_df)} lignes")
            
            return train_df, val_df, test_df
            
        except FileNotFoundError as e:
            logger.error(f"‚ùå Fichiers de donn√©es non trouv√©s: {e}")
            logger.error("üí° Ex√©cutez d'abord l'ingestion des donn√©es")
            return None, None, None
    
    def prepare_features(self, df):
        """Pr√©pare les features et la target"""
        # Exclure la colonne Time qui peut causer des probl√®mes num√©riques
        feature_cols = [col for col in df.columns if col not in ['Class', 'Time']]
        X = df[feature_cols]
        y = df['Class']
        
        # Nettoyer les valeurs inf et nan
        X = X.replace([np.inf, -np.inf], np.nan)
        X = X.fillna(X.median())
        
        return X, y
    
    def calculate_metrics(self, y_true, y_pred, y_pred_proba=None):
        """Calcule les m√©triques d'√©valuation"""
        metrics = {
            'accuracy': accuracy_score(y_true, y_pred),
            'precision': precision_score(y_true, y_pred, zero_division=0),
            'recall': recall_score(y_true, y_pred, zero_division=0),
            'f1': f1_score(y_true, y_pred, zero_division=0),
        }
        
        if y_pred_proba is not None:
            try:
                metrics['roc_auc'] = roc_auc_score(y_true, y_pred_proba)
            except ValueError:
                metrics['roc_auc'] = 0.5
        
        return metrics
    
    def safe_mlflow_log(self, func, *args, **kwargs):
        """Wrapper s√©curis√© pour MLflow"""
        if not self.mlflow_enabled:
            return
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è MLflow warning: {e}")
    
    def train_random_forest_simple(self, X_train, y_train, X_val, y_val):
        """Entra√Æne un Random Forest simple et robuste"""
        
        if self.mlflow_enabled:
            run = mlflow.start_run(run_name=f"random_forest_{datetime.now().strftime('%H%M%S')}")
        
        try:
            logger.info("üß† Entra√Ænement - Random Forest (Simple)")
            
            # Mod√®le robuste avec gestion du d√©s√©quilibre
            model = RandomForestClassifier(
                n_estimators=100,
                max_depth=15,
                min_samples_split=10,
                min_samples_leaf=5,
                random_state=42,
                class_weight='balanced',  # Gestion automatique du d√©s√©quilibre
                n_jobs=-1
            )
            
            # Entra√Ænement
            model.fit(X_train, y_train)
            
            # Pr√©dictions
            y_pred = model.predict(X_val)
            y_pred_proba = model.predict_proba(X_val)[:, 1]
            
            # M√©triques
            metrics = self.calculate_metrics(y_val, y_pred, y_pred_proba)
            
            # Log MLflow (s√©curis√©)
            self.safe_mlflow_log(mlflow.log_params, {
                'algorithm': 'random_forest_simple',
                'n_estimators': 100,
                'max_depth': 15,
                'class_weight': 'balanced'
            })
            
            for metric_name, metric_value in metrics.items():
                self.safe_mlflow_log(mlflow.log_metric, f"val_{metric_name}", metric_value)
            
            # Sauvegarder localement (backup)
            model_dir = Path("models")
            model_dir.mkdir(exist_ok=True)
            joblib.dump(model, model_dir / "random_forest_model.pkl")
            
            # Feature importance
            feature_importance = pd.DataFrame({
                'feature': X_train.columns,
                'importance': model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            # Log model (s√©curis√©)
            self.safe_mlflow_log(mlflow.sklearn.log_model, model, "model")
            
            logger.info(f"   ‚úÖ ROC-AUC: {metrics['roc_auc']:.4f}")
            logger.info(f"   ‚úÖ Precision: {metrics['precision']:.4f}")
            logger.info(f"   ‚úÖ Recall: {metrics['recall']:.4f}")
            logger.info(f"   ‚úÖ F1-Score: {metrics['f1']:.4f}")
            
            return model, metrics, feature_importance
            
        finally:
            if self.mlflow_enabled:
                mlflow.end_run()
    
    def train_random_forest_with_smote(self, X_train, y_train, X_val, y_val):
        """Entra√Æne un Random Forest avec SMOTE"""
        
        if self.mlflow_enabled:
            run = mlflow.start_run(run_name=f"random_forest_smote_{datetime.now().strftime('%H%M%S')}")
        
        try:
            logger.info("üß† Entra√Ænement - Random Forest (avec SMOTE)")
            
            # SMOTE pour √©quilibrer
            smote = SMOTE(random_state=42, k_neighbors=3)  # R√©duire k_neighbors
            X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)
            
            logger.info(f"   ‚Ä¢ Apr√®s SMOTE: {len(y_train_balanced)} √©chantillons")
            logger.info(f"   ‚Ä¢ Nouvelle distribution: {y_train_balanced.mean():.3%} fraudes")
            
            # Mod√®le
            model = RandomForestClassifier(
                n_estimators=100,
                max_depth=12,
                min_samples_split=5,
                random_state=42,
                n_jobs=-1
            )
            
            # Entra√Ænement
            model.fit(X_train_balanced, y_train_balanced)
            
            # Pr√©dictions
            y_pred = model.predict(X_val)
            y_pred_proba = model.predict_proba(X_val)[:, 1]
            
            # M√©triques
            metrics = self.calculate_metrics(y_val, y_pred, y_pred_proba)
            
            # Log MLflow (s√©curis√©)
            self.safe_mlflow_log(mlflow.log_params, {
                'algorithm': 'random_forest_smote',
                'n_estimators': 100,
                'max_depth': 12,
                'sampling': 'smote'
            })
            
            for metric_name, metric_value in metrics.items():
                self.safe_mlflow_log(mlflow.log_metric, f"val_{metric_name}", metric_value)
            
            # Sauvegarder localement
            model_dir = Path("models")
            model_dir.mkdir(exist_ok=True)
            joblib.dump(model, model_dir / "random_forest_smote_model.pkl")
            
            # Log model (s√©curis√©)
            self.safe_mlflow_log(mlflow.sklearn.log_model, model, "model")
            
            logger.info(f"   ‚úÖ ROC-AUC: {metrics['roc_auc']:.4f}")
            logger.info(f"   ‚úÖ Precision: {metrics['precision']:.4f}")
            logger.info(f"   ‚úÖ Recall: {metrics['recall']:.4f}")
            logger.info(f"   ‚úÖ F1-Score: {metrics['f1']:.4f}")
            
            return model, metrics
            
        finally:
            if self.mlflow_enabled:
                mlflow.end_run()
    
    def train_logistic_regression_robust(self, X_train, y_train, X_val, y_val):
        """Entra√Æne une r√©gression logistique robuste"""
        
        if self.mlflow_enabled:
            run = mlflow.start_run(run_name=f"logistic_robust_{datetime.now().strftime('%H%M%S')}")
        
        try:
            logger.info("üß† Entra√Ænement - R√©gression Logistique (Robuste)")
            
            # Scaler robuste pour √©viter les probl√®mes num√©riques
            scaler = RobustScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_val_scaled = scaler.transform(X_val)
            
            # Mod√®le robuste
            model = LogisticRegression(
                random_state=42,
                max_iter=1000,
                C=0.1,  # R√©gularisation forte
                solver='liblinear',  # Solver robuste
                class_weight='balanced'
            )
            
            # Entra√Ænement
            model.fit(X_train_scaled, y_train)
            
            # Pr√©dictions
            y_pred = model.predict(X_val_scaled)
            y_pred_proba = model.predict_proba(X_val_scaled)[:, 1]
            
            # M√©triques
            metrics = self.calculate_metrics(y_val, y_pred, y_pred_proba)
            
            # Log MLflow (s√©curis√©)
            self.safe_mlflow_log(mlflow.log_params, {
                'algorithm': 'logistic_regression_robust',
                'C': 0.1,
                'solver': 'liblinear',
                'scaling': 'robust'
            })
            
            for metric_name, metric_value in metrics.items():
                self.safe_mlflow_log(mlflow.log_metric, f"val_{metric_name}", metric_value)
            
            # Sauvegarder localement
            model_dir = Path("models")
            model_dir.mkdir(exist_ok=True)
            joblib.dump(model, model_dir / "logistic_robust_model.pkl")
            joblib.dump(scaler, model_dir / "robust_scaler.pkl")
            
            # Log model (s√©curis√©)
            self.safe_mlflow_log(mlflow.sklearn.log_model, model, "model")
            self.safe_mlflow_log(mlflow.sklearn.log_model, scaler, "scaler")
            
            logger.info(f"   ‚úÖ ROC-AUC: {metrics['roc_auc']:.4f}")
            logger.info(f"   ‚úÖ Precision: {metrics['precision']:.4f}")
            logger.info(f"   ‚úÖ Recall: {metrics['recall']:.4f}")
            logger.info(f"   ‚úÖ F1-Score: {metrics['f1']:.4f}")
            
            return model, scaler, metrics
            
        finally:
            if self.mlflow_enabled:
                mlflow.end_run()
    
    def run_training_pipeline(self):
        """Ex√©cute l'entra√Ænement complet"""
        logger.info("üöÄ D√âMARRAGE DE L'ENTRA√éNEMENT")
        
        # Charger les donn√©es
        train_df, val_df, test_df = self.load_data()
        if train_df is None:
            return False
        
        # Pr√©parer les features (sans Time)
        X_train, y_train = self.prepare_features(train_df)
        X_val, y_val = self.prepare_features(val_df)
        X_test, y_test = self.prepare_features(test_df)
        
        logger.info(f"üìä Features utilis√©es: {len(X_train.columns)}")
        logger.info(f"üìä D√©s√©quilibre des classes:")
        logger.info(f"   ‚Ä¢ Train - Fraudes: {y_train.mean():.3%}")
        logger.info(f"   ‚Ä¢ Validation - Fraudes: {y_val.mean():.3%}")
        
        results = {}
        
        try:
            # 1. Random Forest simple (plus robuste)
            model1, metrics1, importance1 = self.train_random_forest_simple(X_train, y_train, X_val, y_val)
            results['random_forest_simple'] = metrics1
            
            # 2. Random Forest avec SMOTE
            model2, metrics2 = self.train_random_forest_with_smote(X_train, y_train, X_val, y_val)
            results['random_forest_smote'] = metrics2
            
            # 3. R√©gression logistique robuste
            model3, scaler3, metrics3 = self.train_logistic_regression_robust(X_train, y_train, X_val, y_val)
            results['logistic_robust'] = metrics3
            
            # R√©sum√©
            logger.info("\nüìä R√âSUM√â DES PERFORMANCES:")
            for model_name, metrics in results.items():
                logger.info(f"   {model_name}:")
                logger.info(f"     ‚Ä¢ ROC-AUC: {metrics['roc_auc']:.4f}")
                logger.info(f"     ‚Ä¢ Precision: {metrics['precision']:.4f}")
                logger.info(f"     ‚Ä¢ Recall: {metrics['recall']:.4f}")
                logger.info(f"     ‚Ä¢ F1-Score: {metrics['f1']:.4f}")
            
            # Meilleur mod√®le
            best_model = max(results.items(), key=lambda x: x[1]['roc_auc'])
            logger.info(f"\nüèÜ MEILLEUR MOD√àLE: {best_model[0]} (ROC-AUC: {best_model[1]['roc_auc']:.4f})")
            
            # Sauvegarder le r√©sum√©
            results_df = pd.DataFrame(results).T
            results_df.to_csv("models/training_results.csv")
            logger.info("üìÑ R√©sultats sauvegard√©s dans models/training_results.csv")
            
            logger.info("‚úÖ ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'entra√Ænement: {e}")
            return False

def main():
    """Fonction principale"""
    
    print("üß† ENTRA√éNEMENT ROBUSTE - D√âTECTION DE FRAUDE")
    print("=" * 50)
    
    # V√©rifier les packages
    try:
        import sklearn
        import mlflow
        from imblearn.over_sampling import SMOTE
        print("‚úÖ Packages ML OK")
    except ImportError as e:
        print(f"‚ùå Package manquant: {e}")
        print("üí° Installez avec: pip3 install imbalanced-learn")
        return
    
    # Entra√Æner les mod√®les
    trainer = RobustFraudTrainer()
    success = trainer.run_training_pipeline()
    
    if success:
        print("\nüéâ ENTRA√éNEMENT R√âUSSI!")
        print("üìä Consultez MLflow: http://localhost:5001")
        print("üíæ Mod√®les sauvegard√©s dans models/")
        print("üìÑ R√©sultats dans models/training_results.csv")
    else:
        print("\n‚ùå √âCHEC DE L'ENTRA√éNEMENT")
        print("üí° V√©rifiez que l'ingestion des donn√©es a √©t√© faite")

if __name__ == "__main__":
    main()